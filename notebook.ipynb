{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Preprocess\n",
    "import parameters as PRM\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "* https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "* https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fasttext embeddings\n",
    "* This cell shows how to load fasttext embeddings.\n",
    "* We set the PRM.MAX_NB_VECTOR parameter to 10 which means that we load only the first 10 words of the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocess()\n",
    "PRM.MAX_NB_VECTOR = 10 # size of the embeddings's voccabulary\n",
    "p.load_fasttext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We print the dictionary containing the english vocabuary and the vocab objects and we see that the vocabulary's size is 10.\n",
    "* We see that the word ',' is at index 0, it is the first word of the vocabulary.\n",
    "* We print the vector which represent the word ','.\n",
    "* We print all the vectors of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': <gensim.models.keyedvectors.Vocab object at 0x0000020704172828>, 'the': <gensim.models.keyedvectors.Vocab object at 0x0000020704173198>, '.': <gensim.models.keyedvectors.Vocab object at 0x0000020704172898>, 'and': <gensim.models.keyedvectors.Vocab object at 0x00000207041734A8>, 'to': <gensim.models.keyedvectors.Vocab object at 0x00000207041728D0>, 'of': <gensim.models.keyedvectors.Vocab object at 0x0000020704173240>, 'a': <gensim.models.keyedvectors.Vocab object at 0x000002070416E048>, '</s>': <gensim.models.keyedvectors.Vocab object at 0x0000020704173BE0>, 'in': <gensim.models.keyedvectors.Vocab object at 0x000002070416E0B8>, 'is': <gensim.models.keyedvectors.Vocab object at 0x0000020704173B70>}\n",
      "\n",
      "Vocab(count:10, index:0)\n",
      "\n",
      "[ 1.2500e-01 -1.0790e-01  2.4500e-02 -2.5290e-01  1.0570e-01 -1.8400e-02\n",
      "  1.1770e-01 -7.0100e-02 -4.0100e-02 -8.0000e-03  7.7200e-02 -2.2600e-02\n",
      "  8.9300e-02 -4.8700e-02 -8.9700e-02 -8.3500e-02  2.0000e-02  2.7300e-02\n",
      " -1.9400e-02  9.6400e-02  8.7500e-02  9.8000e-03  4.5300e-02  1.5500e-02\n",
      "  1.4620e-01  2.2500e-02  4.4800e-02  1.3700e-02  5.7000e-02  1.7640e-01\n",
      " -1.0720e-01 -8.2600e-02  1.7300e-02  1.0900e-01  2.0700e-02 -1.2710e-01\n",
      "  2.4450e-01  3.7500e-02 -2.0900e-02 -4.4500e-02  5.4000e-02  1.2820e-01\n",
      "  4.3700e-02  5.8800e-02  9.8400e-02  5.3900e-02  4.0000e-04  1.2900e-01\n",
      "  2.4200e-02 -1.2000e-02 -4.8000e-02  3.4600e-02 -6.6400e-02 -3.3000e-02\n",
      " -6.2500e-02 -7.0800e-02 -5.7900e-02  1.7380e-01  4.4480e-01  3.7000e-02\n",
      " -1.0010e-01 -3.2000e-03  3.5900e-02 -6.8500e-02 -3.6100e-02  7.0000e-03\n",
      "  1.3160e-01 -9.4500e-02 -6.1000e-02  1.7800e-02 -7.6300e-02 -1.9200e-02\n",
      "  3.3000e-03  5.6000e-03  1.8780e-01 -7.5400e-02 -9.5000e-03  4.4600e-02\n",
      " -5.8800e-02  2.4400e-02 -2.5100e-02 -4.9300e-02  3.0800e-02 -3.5900e-02\n",
      " -1.8840e-01 -9.8800e-02  1.8870e-01  4.5900e-02 -8.1600e-02 -1.5240e-01\n",
      " -3.7500e-02 -6.9200e-02  4.2700e-02 -4.7100e-02 -8.6000e-03 -2.1900e-01\n",
      " -6.4000e-03  8.7700e-02 -7.4000e-03 -1.4000e-01 -1.5600e-02  1.6100e-02\n",
      "  1.0400e-01 -1.4450e-01 -7.1900e-02 -1.4400e-02 -2.9300e-02 -1.2600e-02\n",
      "  6.1900e-02 -3.7300e-02 -1.4710e-01 -2.5520e-01 -6.8500e-02  2.8920e-01\n",
      " -2.7500e-02  4.3600e-02  3.1100e-02  2.4900e-02  1.4200e-02  4.0300e-02\n",
      "  1.7290e-01  2.3000e-03 -2.5500e-02 -2.1200e-02  7.0100e-02 -7.2700e-02\n",
      "  2.7900e-02  1.1510e-01 -3.9400e-02 -9.6200e-02 -5.9800e-02 -4.5900e-02\n",
      " -3.2600e-02 -2.3170e-01  9.4500e-02  1.1000e-02 -2.5110e-01  1.0870e-01\n",
      " -6.9900e-02  3.5900e-02  2.0800e-02 -5.3600e-02  4.7800e-02  1.7800e-02\n",
      "  9.5000e-03  3.5400e-02 -7.7260e-01 -7.9000e-02  4.7200e-02  5.8400e-02\n",
      " -1.0130e-01  4.4800e-02 -1.2020e-01  3.7600e-02  5.1000e-02 -6.1600e-02\n",
      "  4.3210e-01  1.7900e-02  2.6300e-02  2.7100e-02  4.7300e-02 -9.5100e-02\n",
      " -2.2610e-01  2.6100e-02  2.6200e-02 -2.3500e-02 -3.6900e-02 -1.6550e-01\n",
      " -6.9700e-02  1.2200e-02 -3.0300e-02  4.2700e-02  7.8700e-02 -3.6000e-02\n",
      "  2.0600e-02 -6.8000e-03  1.2570e-01  4.4700e-02 -7.7600e-02 -1.1220e-01\n",
      " -2.9100e-02  4.6540e-01  1.0100e-01  4.4400e-01  9.5000e-03  1.3120e-01\n",
      "  7.6600e-02  8.7300e-02 -8.7800e-02 -2.9600e-02  4.6000e-03  4.1600e-02\n",
      " -1.3400e-02  5.7100e-02 -1.0900e-02 -6.5500e-02  8.2000e-03 -5.6300e-02\n",
      " -8.3000e-02 -5.5000e-02 -6.8800e-02  9.1000e-03 -6.7700e-02 -1.0010e-01\n",
      "  2.0000e-02 -9.7900e-02  1.1340e-01 -1.8800e-02  1.3600e-02  7.8200e-02\n",
      "  2.0700e-02  1.3300e-02 -4.9200e-02 -1.3900e-02  1.2300e-02  3.6000e-02\n",
      "  1.2490e-01  5.0300e-02  1.5000e-03  1.2460e-01 -8.9700e-02 -1.2100e-02\n",
      " -1.8200e-02  2.2450e-01 -3.1300e-02 -1.5960e-01  7.3000e-03 -7.7200e-02\n",
      " -8.3000e-02 -7.1600e-02  1.1200e-02  2.1800e-02  1.2450e-01 -3.6100e-02\n",
      "  3.1200e-02  6.5200e-02  5.6000e-02  6.7000e-02  7.0900e-02 -2.4800e-02\n",
      "  4.4900e-02 -1.2960e-01  1.4080e-01 -3.5900e-02  1.1585e+00  2.7000e-03\n",
      "  1.8500e-02  5.4900e-02  1.3670e-01  2.7420e-01 -4.7200e-02 -4.1400e-02\n",
      " -5.4800e-02 -9.1100e-02 -1.5000e-03 -1.6130e-01  1.7900e-02 -4.0000e-03\n",
      "  6.1000e-02  5.5900e-02  1.1380e-01  2.9780e-01 -1.5110e-01 -7.9000e-03\n",
      " -8.3800e-02  2.9600e-02 -1.0410e-01  1.6270e-01 -6.7000e-02  5.0400e-02\n",
      " -4.2000e-02 -2.0000e-03  1.8400e-01  5.9600e-02  4.4800e-02  9.8900e-02\n",
      " -2.1570e-01 -1.1700e-02  2.1420e-01 -1.6720e-01 -4.4400e-02  2.0450e-01\n",
      " -4.6200e-01 -4.8200e-02  6.8800e-02 -3.0400e-02  4.7800e-02  1.5830e-01\n",
      "  9.2000e-02  9.4900e-02  6.5000e-02 -3.9800e-02 -1.3760e-01 -4.3600e-02\n",
      "  5.7800e-02  1.8800e-02  1.4800e-02  2.3050e-01 -6.9600e-02 -2.1500e-02]\n",
      "\n",
      "[[ 1.250e-01 -1.079e-01  2.450e-02 ...  2.305e-01 -6.960e-02 -2.150e-02]\n",
      " [-5.170e-02  7.400e-02 -1.310e-02 ...  2.370e-01  4.000e-04 -4.200e-03]\n",
      " [ 3.420e-02 -8.010e-02  1.162e-01 ...  5.423e-01 -6.240e-02  9.000e-02]\n",
      " ...\n",
      " [ 7.310e-02 -2.430e-01 -3.530e-02 ...  4.093e-01 -9.320e-02 -4.610e-02]\n",
      " [-1.400e-02 -2.522e-01  7.150e-02 ...  1.370e-01  4.500e-03  3.290e-02]\n",
      " [-9.780e-02 -2.083e-01 -1.037e-01 ... -2.282e-01 -2.244e-01  8.900e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(p.EN_vec.vocab)\n",
    "print()\n",
    "print(p.EN_vec.vocab[','])\n",
    "print()\n",
    "print(p.EN_vec[','])\n",
    "print()\n",
    "print(p.EN_vec.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We convert the english vectors into a torch tensor which is call weights.\n",
    "* We create an embedding layer from the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2500e-01, -1.0790e-01,  2.4500e-02,  ...,  2.3050e-01,\n",
      "         -6.9600e-02, -2.1500e-02],\n",
      "        [-5.1700e-02,  7.4000e-02, -1.3100e-02,  ...,  2.3700e-01,\n",
      "          4.0000e-04, -4.2000e-03],\n",
      "        [ 3.4200e-02, -8.0100e-02,  1.1620e-01,  ...,  5.4230e-01,\n",
      "         -6.2400e-02,  9.0000e-02],\n",
      "        ...,\n",
      "        [ 7.3100e-02, -2.4300e-01, -3.5300e-02,  ...,  4.0930e-01,\n",
      "         -9.3200e-02, -4.6100e-02],\n",
      "        [-1.4000e-02, -2.5220e-01,  7.1500e-02,  ...,  1.3700e-01,\n",
      "          4.5000e-03,  3.2900e-02],\n",
      "        [-9.7800e-02, -2.0830e-01, -1.0370e-01,  ..., -2.2820e-01,\n",
      "         -2.2440e-01,  8.9000e-02]])\n",
      "\n",
      "Embedding(10, 300)\n",
      "\n",
      "tensor([[-5.1700e-02,  7.4000e-02, -1.3100e-02,  4.4700e-02, -3.4300e-02,\n",
      "          2.1200e-02,  6.9000e-03, -1.6300e-02, -1.8100e-02, -2.0000e-03,\n",
      "         -1.0210e-01,  5.9000e-03,  2.5700e-02, -2.6000e-03, -5.8600e-02,\n",
      "         -3.7800e-02,  1.6300e-02,  1.4600e-02, -8.8000e-03, -1.7600e-02,\n",
      "         -8.5000e-03, -7.8000e-03, -1.8300e-02,  8.8000e-03,  1.3000e-03,\n",
      "         -9.3800e-02,  1.3900e-02,  1.4900e-02, -3.9400e-02, -2.9400e-02,\n",
      "          9.4000e-03, -2.5200e-02, -1.0400e-02, -2.2130e-01, -2.2900e-02,\n",
      "         -8.9000e-03, -3.2200e-02,  8.2200e-02,  2.1000e-03,  2.8200e-02,\n",
      "          7.2000e-03, -9.1000e-03, -3.5200e-02, -1.7800e-02, -7.0600e-02,\n",
      "          6.3000e-02, -9.2000e-03, -2.2300e-02, -5.6000e-03,  5.1500e-02,\n",
      "         -3.0700e-02,  4.3600e-02, -1.1000e-02, -5.5500e-02,  8.9000e-03,\n",
      "         -6.7300e-02,  1.0500e-02,  5.7400e-02,  9.9000e-03, -2.8300e-02,\n",
      "          4.7000e-02,  5.3000e-03,  3.0000e-03,  7.0000e-04,  4.4300e-02,\n",
      "          6.9000e-03, -3.3400e-02,  9.1000e-03, -7.6000e-03,  6.6000e-03,\n",
      "          9.1700e-02,  3.1100e-02,  5.4300e-02,  2.8200e-02, -2.0000e-02,\n",
      "         -3.3400e-02,  5.3000e-03,  3.6400e-02,  2.2490e-01,  9.2800e-02,\n",
      "         -1.2300e-02,  8.6000e-03, -5.9900e-02,  6.7600e-02,  4.0200e-02,\n",
      "          1.2000e-03,  4.6400e-02, -4.3700e-02,  5.9000e-03,  9.1700e-02,\n",
      "         -4.1200e-02, -1.5100e-02, -2.3100e-02,  9.5000e-03,  5.8800e-02,\n",
      "          2.7900e-02,  6.4700e-02, -5.6800e-02, -1.3000e-02,  4.7400e-02,\n",
      "          3.5400e-02, -1.2100e-02, -7.7000e-03, -1.3060e-01,  1.3400e-02,\n",
      "         -5.0600e-02,  1.1100e-02,  1.1900e-02, -2.2100e-02,  3.9400e-02,\n",
      "          2.2100e-02,  2.4500e-02,  3.9000e-03,  1.1460e-01,  2.2800e-02,\n",
      "         -4.6800e-02, -4.5900e-02, -1.8900e-02,  7.6000e-03, -3.0200e-02,\n",
      "         -3.4800e-02, -2.8900e-02, -3.9900e-02,  2.4500e-02, -1.0200e-02,\n",
      "          5.7800e-02, -3.8800e-02, -1.1700e-02, -3.0400e-02,  2.4660e-01,\n",
      "         -1.1100e-02,  3.5600e-02,  4.6000e-03,  2.0940e-01, -1.0220e-01,\n",
      "          3.3600e-02,  6.8800e-02, -7.0800e-02,  2.6900e-02, -4.2300e-02,\n",
      "          7.7000e-03, -2.6700e-02,  7.2000e-03,  3.5000e-03,  3.5100e-02,\n",
      "         -6.3000e-03, -4.4620e-01,  1.0500e-02, -1.2000e-02, -4.4900e-02,\n",
      "         -1.6960e-01,  5.0400e-02,  9.3000e-02, -4.4000e-03, -4.1000e-03,\n",
      "          3.2200e-02,  2.0260e-01,  6.1300e-02, -2.9500e-02,  2.2800e-02,\n",
      "         -1.9000e-02,  1.7300e-02,  1.4800e-01, -1.7500e-02, -1.2500e-02,\n",
      "          6.8700e-02,  3.3300e-02, -3.0300e-02,  4.2800e-02,  5.1000e-03,\n",
      "          2.2800e-02,  1.0400e-02,  7.3100e-02,  7.9000e-03, -5.1000e-03,\n",
      "          5.4300e-02, -3.2500e-02,  5.1200e-02,  2.8800e-02, -5.8600e-02,\n",
      "         -0.0000e+00,  4.9300e-02,  1.6600e-02, -1.4300e-02,  3.5900e-02,\n",
      "          5.4300e-02, -5.0000e-04, -5.8900e-02,  1.6200e-02, -2.2200e-02,\n",
      "         -1.9900e-02,  2.3500e-02, -6.7800e-02,  1.7900e-02,  3.3000e-03,\n",
      "          1.1400e-02,  4.7300e-02, -4.4300e-02,  3.2300e-02,  1.9500e-02,\n",
      "         -6.4700e-02,  3.3880e-01,  6.9900e-02, -2.1500e-02, -2.4400e-02,\n",
      "         -3.4000e-03, -3.4000e-03, -6.2200e-02,  1.2300e-02,  3.7500e-02,\n",
      "         -1.9700e-02,  2.4100e-02, -8.7700e-02,  2.0100e-02, -6.1000e-03,\n",
      "         -2.5600e-02, -1.9100e-02, -2.6400e-02,  1.9000e-02, -4.2200e-02,\n",
      "          2.5100e-02,  8.2500e-02, -9.6000e-03,  1.2880e-01,  6.2100e-02,\n",
      "          5.3800e-02,  1.8900e-02,  4.2200e-02,  1.8030e-01, -1.0000e-03,\n",
      "         -3.2800e-02, -5.5900e-02, -1.5700e-02,  4.9000e-02,  3.5200e-02,\n",
      "         -4.1700e-02,  1.5900e-02, -7.6600e-02, -6.5700e-02,  4.9700e-02,\n",
      "          1.0200e-02,  1.4710e-01, -7.1100e-02, -1.4690e-01,  4.7370e-01,\n",
      "         -1.6900e-02, -5.1000e-03,  1.5900e-02,  5.5000e-02, -6.3400e-02,\n",
      "         -2.1000e-02,  1.2200e-02,  2.6900e-02,  6.0000e-03,  6.6400e-02,\n",
      "          1.0600e-02, -7.0500e-02, -2.0700e-02, -7.8400e-02, -2.9100e-02,\n",
      "         -2.8300e-02, -1.5680e-01, -3.9300e-02,  5.0000e-03,  2.0400e-02,\n",
      "         -2.6000e-03,  4.3600e-02,  2.7900e-02, -3.9300e-02,  3.6700e-02,\n",
      "         -4.2000e-03, -1.5600e-02, -7.3300e-02, -1.6370e-01,  6.5200e-02,\n",
      "         -6.2000e-03, -6.5000e-02, -1.9840e-01, -4.1100e-02, -1.5340e-01,\n",
      "          2.0000e-03,  1.3300e-02, -2.3640e-01, -5.2800e-02, -4.2000e-03,\n",
      "         -4.4700e-02,  1.1200e-02, -3.3200e-02, -5.5000e-02,  1.3000e-03,\n",
      "          1.6900e-02, -4.3900e-02, -5.7800e-02,  2.2300e-02, -7.7700e-02,\n",
      "         -4.3200e-02, -2.5100e-02,  2.3700e-01,  4.0000e-04, -4.2000e-03]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor(p.EN_vec.vectors)\n",
    "print(weights)\n",
    "emb = nn.Embedding.from_pretrained(weights)\n",
    "print()\n",
    "print(emb)\n",
    "print()\n",
    "print(emb(torch.LongTensor([1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
