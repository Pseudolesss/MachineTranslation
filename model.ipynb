{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from preprocess import Preprocess\n",
    "import parameters as PRM\n",
    "import utils\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     he was chairman of the board of governors at t...\n",
      "1     his was honoured with the naming of the anthon...\n",
      "2     director d  w  griffith was central to the dev...\n",
      "3          some markets lacked sound equipped theaters \n",
      "4     one reason this was possible is that  with so ...\n",
      "5     it was expected that a great deal of money was...\n",
      "6                                                   ed \n",
      "7     each prefix has a unique symbol that is prepen...\n",
      "8              the binary multiple  $     is close to  \n",
      "9     their adoption in popular publications remains...\n",
      "10    however  although some of these are repeated o...\n",
      "11    this is a list of company names with their nam...\n",
      "12      $ th century fox   film studio  formed in  $...\n",
      "13     abn amro   in the  $ s  the nederlandsche han...\n",
      "14    before  $  january  $   the company was called...\n",
      "15     alza   from the name of the founder alex zaff...\n",
      "16     amazon com   founder jeff bezos renamed the c...\n",
      "17    the name is a contraction of alan michael suga...\n",
      "18     arby s   the enunciation of the initials of i...\n",
      "19    the partners wanted to use the name big tex  b...\n",
      "20     arm limited   named after the microprocessor ...\n",
      "21     asics   an acronym for anima sana in corpore ...\n",
      "22     ask com   search engine formerly named after ...\n",
      "23     aston martin   from the  aston hill  races  n...\n",
      "24     at t   the american telephone and telegraph c...\n",
      "25    the founder august horch left the company afte...\n",
      "26     bang   olufsen   from the names of its founde...\n",
      "27     bally   originally lion manufacturing  the co...\n",
      "28             anilin and soda were the first products \n",
      "29     bea systems   from the first initial of each ...\n",
      "Name: target_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "p = Preprocess()\n",
    "p.load_wiki(nb_pair_sentences=30)\n",
    "p.load_fasttext()\n",
    "print(p.sentences[PRM.TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences pairs in the corpus:\n",
      "30\n",
      "\n",
      "Random sentence pair in the corpus:\n",
      "['the partners wanted to use the name big tex  but were unsuccessful in negotiating with the akron businessman who was already using the name ', 'ihre partner wollten den namen  big tex  verwenden  waren aber nicht erfolgreich in der verhandlung mit einem akroner gesch√§ftsmann  der den namen bereits benutzte ']\n",
      "\n",
      "Number of words for each langage in the corpus:\n",
      "en 272\n",
      "de 275\n"
     ]
    }
   ],
   "source": [
    "def prepareData():\n",
    "    input_lang = Lang('en')\n",
    "    output_lang = Lang('de')\n",
    "    pairs = []\n",
    "    for i in range(len(p.sentences)):\n",
    "        pair = []\n",
    "        english_sentence = p.sentences.iloc[i][PRM.TARGET]\n",
    "        german_sentence = p.sentences.iloc[i][PRM.SOURCE]\n",
    "        output_lang.addSentence(german_sentence)\n",
    "        input_lang.addSentence(english_sentence)\n",
    "        pair.append(english_sentence)\n",
    "        pair.append(german_sentence)\n",
    "        pairs.append(pair)\n",
    "    return input_lang, output_lang, pairs\n",
    "input_lang, output_lang, pairs = prepareData()\n",
    "print('Number of sentences pairs in the corpus:')\n",
    "print(len(p.sentences))\n",
    "print()\n",
    "print('Random sentence pair in the corpus:')\n",
    "print(random.choice(pairs))\n",
    "print()\n",
    "print('Number of words for each langage in the corpus:')\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
